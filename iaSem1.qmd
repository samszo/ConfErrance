---
bibliography: ref_iaSem1.bib
lightbox: true
title: "Séminaire IA - 1"
date: "2025/08/05"
author:
  - name: Samuel Szoniecky
    affiliation: Laboratoire Paragraphe - Université Paris 8
    orcid: 0000-0002-7643-3342

citeproc: true

number-sections: true

format: 
  html: 
    theme: default
    search: true
    toc: true
    number-sections: false
    number-depth: 4
    comments:
      hypothesis: true

  pdf: 
    documentclass: scrreprt
    papersize: A4    
    geometry:
          - top=30mm
          - left=20mm
          - heightrounded
    toc: false
    number-sections: false
---

|     |     |     |
|-----|-----|-----|
|     |     |     |

# Atelier pédagogique : utilisation de Ollama et AnythingLLM

L'objectif de cet atelier est de fournir des bases techniques permettant aux participants d'évaluer dans quelles mesures ces technologies peuvent être utiles pour répondre à leurs besoins.

> "Face à la multiplication des logiques de surveillance et de sécurité, de traçage des comportements, de façonnage des désirs et in fine des subjectivités, il s’agirait ainsi de trouver dans une forme d’humanisme renouvelé une ressource pour tenter de penser les moyens d’une reprise de contrôle sur les systèmes intelligents, en mettant le sujet humain au centre du développement technologique." [@levin2024]

## Pourquoi utiliser Ollama

Ollama permet d'exécuter des modèles d'intelligence artificielle localement sur son ordinateur, sans dépendre de services cloud externes. Cela garantit la confidentialité des données, réduit les coûts liés à l'utilisation de l'IA et offre une grande flexibilité pour tester différents modèles open source. De plus, Ollama facilite l'intégration de l'IA dans des projets personnels ou professionnels grâce à une interface simple et des commandes intuitives.

-   Pour plus de détails :
    -   Les sources : <https://github.com/ollama/ollama>
    -   la veille : <https://www.diigo.com/user/luckysemiosis?query=ollama>

## Installation de Ollama

### Installation sur votre ordinateur

#### Pour Windows, macOS et Linux

1.  Rendez-vous sur la page officielle : <https://ollama.com/download>
2.  Téléchargez le programme d'installation adapté à votre système d'exploitation.
3.  Lancez l'installation et suivez les instructions à l'écran.

#### Installation via la ligne de commande (pour les utilisateurs avancés)

-   **macOS (Homebrew) :**

    ``` sh
    brew install ollama
    ```

-   **Linux (script officiel) :**

    ``` sh
    curl -fsSL https://ollama.com/install.sh | sh
    ```

-   **Windows :** Téléchargez l'installateur depuis le site officiel et exécutez-le.

#### Test d'installation

``` sh
ollama --version
```

### Chargement des modèles

-   Exemple : Pour charger un modèle spécifique, utilisez la commande suivante :

``` sh
ollama pull <nom_du_modèle>
```

-   Exemple : pour charger le modèle "llama2"

``` sh
ollama pull llama2
```

#### Liste des modèles disponibles sur votre machine

``` sh
ollama list
```

### Quel modèle choisir ?

Pour choisir un modèle Ollama, il est important de prendre en compte les critères suivants :

1.  **Objectif du projet** : Déterminez si vous avez besoin d'un modèle pour la génération de texte, la classification, la traduction, ou d'autres tâches spécifiques.

2.  **Taille du modèle** : Les modèles plus grands, comme LLaMA 2-13B, offrent généralement de meilleures performances, mais nécessitent plus de ressources (mémoire et puissance de calcul). Si vous travaillez sur une machine avec des ressources limitées, privilégiez un modèle plus léger.

3.  **Données d'entraînement** : Vérifiez si le modèle a été entraîné sur des données pertinentes pour votre domaine d'application. Par exemple, certains modèles sont spécialisés dans des domaines comme la médecine, le droit, ou la programmation.

4.  **Licence et restrictions** : Assurez-vous que la licence du modèle est compatible avec votre utilisation (personnelle, académique, ou commerciale).

5.  **Compatibilité avec Ollama** : Consultez la documentation officielle ou utilisez la commande suivante pour voir les modèles compatibles avec Ollama : https://ollama.com/search\](https://ollama.com/search)

6.  **Tests et évaluation** : Une fois le modèle téléchargé, effectuez des tests pour évaluer ses performances sur vos cas d'utilisation spécifiques.

En cas de doute, commencez par un modèle généraliste comme "llama2" et ajustez votre choix en fonction des résultats obtenus.

Pour plus d'infos cf. [https://shs.cairn.info/revue-francaise-de-sociologie-2014-3-page-563?lang=fr]()

## Usages et limites

### Usage en ligne de commande

1.  **lancer ollama** :

``` sh
ollama serve
```

2.  **Utiliser un modèle** :

``` sh
ollama run deepseek-r1
```

3.  **Commencer une conversation** :

``` sh
A quoi servent les humanités numériques ?
```

La réponse s'affiche dans le terminal :

``` sh
Thinking...
Hmm, l'utilisateur demande à quoi servent les humanités numériques. C'est 
une question assez large mais pertinente sur un domaine émergent dans le 
monde académique.

Je me demande si l'utilisateur est un étudiant en lettres qui explore ce 
sujet pour la première fois, ou peut-être un professionnel curieux de 
comprendre comment ces disciplines s'adaptent aux technologies modernes. 
La question semble simple mais elle cache probablement une interrogation 
sur la pertinence des humanités dans notre époque numérique.

Bon, commençons par rappeler que les humanités numériques ne sont pas 
simplement "les humanités avec un ordinateur". C'est un bouleversement 
fondamental de la manière d'aborder ces études. Je devrais structurer ma 
réponse en plusieurs axes clés plutôt qu'une simple liste.

D'abord, il faut souligner le changement de paradigme : les humanités ne 
sont plus seulement des études traditionnelles mais utilisent maintenant 
des méthodes numériques. L'utilisateur pourrait se demander si c'est juste 
un gadget technologique ou une réelle transformation intellectuelle.

Ensuite, je devrais mentionner l'accessibilité - parce que c'est souvent 
le point négligé dans ces discussions. Les archives sont accessibles à des 
millions d'étudiants et de chercheurs qui n'en auraient pas autrement. 
Cela répond peut-être à une préoccupation plus large sur l'accès aux 
connaissances.

Ah, et les analyses quantitatives ! Beaucoup de gens perçoivent encore les 
humanités comme strictement qualitativas. Mais en réalité, des outils 
comme le texte analytique outext-mining permettent de poser des questions 
nouvelles sur les œuvres littéraires par exemple.

Je devrais aussi parler de la collaboration entre chercheurs - parce que 
l'utilisateur semble intéressé par l'impact sociétal. Les projets 
collaboratifs internationaux sont un aspect important souvent sous-estimé.

Et bien sûr, le rôle dans la critique culturelle est crucial. Dans notre 
société numérique hyper-accommodée, les humanités numériques offrent une 
perspective nécessaire sur comment ces technologies façonnent nos pensées 
et nos valeurs.

Je sens que l'utilisateur pourrait avoir besoin d'exemples concrets pour 
comprendre concrètement l'utilité de ce domaine. Je devrais inclure 
quelques applications pratiques tout au long de ma réponse plutôt que 
juste des concepts abstraits.

Finalement, je dois souligner que les humanités numériques ne remplacent 
pas la lecture physique ou le travail manuel - c'est une complémentation, 
non une substitution. Cela répond peut-être à un préjugé qui circule sur 
ce sujet.
...done thinking.
```

Les **humanités numériques** (ou *digital humanities*) sont un domaine 
interdisciplinaire qui combine les méthodes et les approches des humanités 
traditionnelles avec les technologies numériques.

Voici leurs principales utilisations et objectifs :

1.  **Étude du numérique lui-même :**
    *   **Analyse des phénomènes numériques culturels :** Examiner comment 
le numérique influence la création, la distribution, la réception et 
l'interprétation culturelle (textes, images, sons, films).
    *   **Comprendre les implications sociales :** Explorer comment les 
technologies numériques modifient nos modes de vie, notre communication, 
notre accès aux informations, notre travail intellectuel.

2.  **Mise à disposition du patrimoine culturel :**
    *   **Numérisation d'archives et manuscrits :** Présenter en ligne des 
documents historiques, littéraires, artistiques ou musicaux qui seraient 
autrement difficiles d'accès.
    *   **Accès universelisé :** Rendre le patrimoine culturel accessible 
à un public plus large, indépendamment de l'endroit ou du moment où il se 
trouve.

3.  **Analyse et recherche avancée :**
    *   **Traitement automatique des textes (text mining) :** Utiliser des 
logiciels pour analyser des corpus littéraires, historiques ou 
philosophiques très volumineux ("analyse de fouille de texte") pour 
identifier des thèmes, des tendances, des styles stylistiques ou effectuer 
une cooccurrence.
    *   **Analyse d'images et multimédias :** Développer ou utiliser des 
outils pour étudier les images numériques (recognition faciale dans l'art 
classique ? analyse de style visuel ?), le cinéma, la photographie 
numérique.

4.  **Création et innovation :**
    *   **Hypertexte et multimodalité :** Exploiter la nature non linéaire 
du numérique pour créer de nouvelles formes d'expression artistique ou 
littéraire (oeuvres hypertextuelles, projets multimodaux).
    *   **Représentation visuelle des données complexes :** Développer des 
outils pour visualiser graphiquement des concepts humanitaires difficiles 
à appréhender, comme la chronologie historique, les relations entre 
personnages dans un texte shakespearien, ou l'évolution d'un corpus 
linguistique.

5.  **Collaboration et partage :**
    *   **Projets collaboratifs en ligne :** Faciliter la collaboration 
entre chercheurs du monde entier sur des bases de données communes (comme 
le projet Gallica).
    *   **Veille numérique :** Permettre aux chercheurs d'observer, 
analyser et documenter l'utilisation publique des technologies numériques.

6.  **Rédaction et diffusion électronique :**
    *   **Édition numérique :** Proposer de nouvelles méthodes pour éditer 
et présenter les textes anciens ou modernes.
    *   **Diffusion des travaux académiques :** Publier des recherches, 
des conférences ou des ressources pédagogiques numériques en open access.

7.  **Enseignement :**
    *   **Ressources pédagogiques interactives :** Développer des outils 
et des méthodes d'enseignement innovants utilisant le numérique.
    *   **Préservation du savoir :** Numériser les contenus pédagogiques 
pour assurer leur préservation.

En résumé, les humanités numériques servent à :
*   Explorer de nouvelles formes de culture et d'expression engendrées par 
le numérique.
*   Étudier l'impact sociétal des technologies numériques.
*   Démocratiser l'accès aux connaissances et au patrimoine culturel.
*   Développer de nouvelles méthodes analytiques pour traiter les données 
textuelles, visuelles ou sonores issues du numérique ou adaptées à la 
recherche humaniste.
*   Innover dans la création artistique/littéraire et le travail 
intellectuel.
*   Améliorer l'enseignement des humanités.

Elles ne remplacent pas les humanités traditionnelles (lire, analyser, 
interpréter) mais les enrichissent techniquement, méthodologiquement et 
accessiblement.

4.  **Finir une conversation** : Quitter le terminal

### Extraction de données dans une image

Ces exemples sont liés au projet de recherche "Freloche" qui a pour objectif de cartographier les souvenirs en mettant en scène les analogies du jardin et de la chasse aux papillons pour stimuler les réactions mémorielles des participants avec des images issues de collections numérisées.

-   Nous menons une archéologie des créations à Paris 8 en :
    -   concevant un environnement numérique de captation des souvenirs et d’exploration des récits mémoriels...
    -   initiant un dialogue à travers le temps (la mellification) qui prend plusieurs formes : focus groupe, entretiens individuels...

Dans ce cadre, nous voulons explorer les bibliothèques des participants pour créer des relations entre eux sur la base de références communes.

-   Exemple de scénario à mettre en place pour cette mise en relation.
    1.  demander aux participants de photographier les étagères de leur bibliothèque à partir d'une application qui ajoute la photo dans une base de données
    2.  traiter la photo pour en extraire une liste de livre
    3.  rendre la photo cliquable pour que chaque livre renvoie sa référence
    4.  proposer la photo aux autres participants pour qu'ils réagissent

L'étape 2. qui consiste à identifier chaque livre présent sur l'étagère est très fastidieuse si elle se fait à la main :

{{< video https://youtu.be/wUE-FpwcT20 >}}

Comment utiliser l'IA pour faire ce travail ?

#### Ollama-OCR

"Ollama-OCR" est une application de reconnaissance optique de caractères (OCR, pour Optical Character Recognition). Ollama-OCR s'utilise à partir d'un script Python conçu pour effectuer des tâches d'OCR, en utilisant des modèles d'intelligence artificielle ou des outils spécifiques.

1.  **Installation** : suivre les instructions de cette page : <https://github.com/imanoop7/Ollama-OCR>

2.  **Créer un script python** : one.py

3.  **modifier le script python** :

``` python
from ollama_ocr import OCRProcessor

# Initialize OCR processor
ocr = OCRProcessor(model_name='llama3.2-vision:11b')  # You can use any vision model available on Ollama

# Process an image
result = ocr.process_image(
    image_path="/Users/samszo/Sites/freloche/files/Photos-1-001/PXL_20250225_075552954.MP.jpg", # path to your pdf files "path/to/your/file.pdf"
    format_type="markdown",  # Options: markdown, text, json, structured, key_value
    custom_prompt="Extract all text, focusing on names or book title.", # Optional custom prompt
    language="French" # Specify the language of the text
)
print(result)
```

4.  **Executer le script python** :

``` sh
python one.py
```

5.  **Le résultat s'affiche dans le terminal** :

``` sh
The image presents a black-and-white photograph of a bookshelf, showcasing a collection of books with their spines facing outward. The books are arranged in a row, with some titles and authors visible, while others are not.

Here is the list of books extracted from the image:

*   "La Vie Algorithmique" by Éric Sabir
*   "Pour Une Ecologie de L'attention" by Yves Citton
*   "La Couleur Des Idees" by Yves Citton
*   "Bibliothèque Idées" by Hans Robert Jauß
*   "La Vie Algorithmique" by Éric Sabir
*   "Pour Une Ecologie de L'attention" by Yves Citton
*   "La Couleur Des Idees" by Yves Citton
*   "Bibliothèque Idées" by Hans Robert Jauß
*   "La Vie Algorithmique" by Éric Sabir
*   "Pour Une Ecologie de L'attention" by Yves Citton
*   "La Couleur Des Idees" by Yves Citton
*   "Bibliothèque Idées" by Hans Robert Jauß
*   "La Vie Algorithmique" by Éric Sabir
*   "Pour Une Ecologie de L'attention" by Yves Citton
*   "La Couleur Des Idees" by Yves Citton
*   "Bibliothèque Idées" by Hans Robert Jauß
*   "La Vie Algorithmique" by Éric Sabir
*   "Pour Une Ecologie de L'attention" by Yves Citton
*   "La Couleur Des Idees" by Yves Citton
*   "Bibliothèque Idées" by Hans Robert Jauß
*   "La Vie Algorithmique" by Éric Sabir
*   "Pour Une Ecologie de L'attention" by Yves Citton
*   "La Couleur Des Idees" by Yves Citton
*   "Bibliothèque Idées" by Hans Robert Jauß
*   "La Vie Algorithmique" by Éric Sabir
*   "Pour Une Ecologie de L'attention" by Yves Citton
*   "La Couleur Des Idees" by Yves Citton
*   "Bibliothèque Idées" by Hans Robert Jauß
*   "La Vie Algorithmique" by Éric Sabir
*   "Pour Une Ecologie de L'attention" by Yves Citton
*   "La Couleur Des Idees" by Yves Citton
*   "Bibliothèque Idées" by Hans Robert Jauß
*   "La Vie Algorithmique" by Éric Sabir
*   "Pour Une Ecologie de L'attention" by Yves Citton
*   "La Couleur Des Idees" by Yves Citton
*   "Bibliothèque Idées" by Hans Robert Jauß
*   "La Vie Algorithmique" by Éric Sabir
*   "Pour Une Ecologie de L'attention" by Yves Citton
*   "La Couleur Des Idees" by Yves Citton
*   "Bibliothèque Idées" by Hans Robert Jauß
*   "La Vie Algorithmique" by Éric Sabir
*   "Pour Une Ecologie de L'attention" by Yves Citton
*   "La Couleur Des Idees" by Yves Citton
*   "Bibliothèque Idées" by Hans Robert Jauß
*   "La Vie Algorithmique" by Éric Sabir
*   "Pour Une Ecologie de L'attention" by Yves Citton
*   "La Couleur Des Idees" by Yves Citton
*   "Bibliothèque Idées" by Hans Robert Jauß
*   "La Vie Algorithmique" by Éric Sabir
*   "Pour Une Ecologie de L'attention" by Yves Citton
*   "La Couleur Des Idees" by Yves Citton
*   "Bibliothèque Idées" by Hans Robert Jauß
*   "La Vie Algorithmique" by Éric Sabir
*   "Pour Une Ecologie de L'attention" by Yves Citton
*   "La Couleur Des Idees" by Yves Citton
*   "Bibliothèque Idées" by Hans Robert Jauß
*   "La Vie Algorithmique" by Éric Sabir
*   "Pour Une Ecologie de L'attention" by Yves Citton
*   "La Couleur Des Idees" by Yves Citton
*   "Bibliothèque Idées" by Hans Robert Jauß
*   "La Vie Algorithmique" by Éric Sabir
*   "Pour Une Ecologie de L'attention" by Yves Citton
*   "La Couleur Des Idees" by Yves Citton
*   "Bibliothèque Idées" by Hans Robert Jauß
*   "La Vie Algorithmique" by Éric Sabir
*   "Pour Une Ecologie de L'attention" by Yves Citton
```

##### résultats

-   le processus de traitement prend du temps
-   le résultat comporte des erreurs :
    -   doublons,
    -   mauvaise orthographe
-   des actions supplémentaires sont nécessaires
    -   optimiser le prompt
    -   tester d'autres modèles
    -   trouver les références ISBN de chaque livre
    -   cartographier la photo pour sélectionner une référence en cliquant sur un livre
    -   intégration du code dans Freloche

#### Gemini

Gemini est une plateforme d'intelligence artificielle développée par Google DeepMind, conçue pour intégrer des capacités avancées de traitement du langage naturel et de raisonnement. Elle combine des modèles de langage de pointe avec des fonctionnalités de planification et de résolution de problèmes, permettant des interactions plus dynamiques et contextuelles.

##### Fonctionnalités principales de Gemini :

1.  **Compréhension contextuelle avancée** : Gemini peut interpréter des requêtes complexes en tenant compte du contexte global.
2.  **Raisonnement multimodal** : Capacité à traiter et à intégrer des données provenant de plusieurs sources (texte, images, etc.).
3.  **Adaptabilité** : Gemini peut être personnalisé pour des cas d'utilisation spécifiques, comme l'éducation, la recherche ou les applications commerciales.
4.  **Sécurité et éthique** : Conçu pour minimiser les biais et garantir des interactions responsables.

##### Applications potentielles :

-   Assistance à la recherche académique.
-   Génération de contenu créatif.
-   Analyse de données complexes.
-   Automatisation des tâches dans des environnements professionnels.

Pour plus d'informations, consultez la page officielle : [Google DeepMind Gemini](https://www.deepmind.com).

##### extraction des références de livre dans une image

{{< video https://youtu.be/qGliyc7ZTso >}}

-   Après des demandes pour :
    -   un traitement de 10 images supplémentaires
    -   une compilation des listes dans une liste unique sans doublons
-   on obtient le résultat suivant <https://docs.google.com/spreadsheets/d/1pRQhTsZtlsM1CV2nANeprvEkq6_Ikm16xbo1tRvBqhE/edit?usp=sharing>

##### résultats

-   le processus est payant : 21 € / mois <https://gemini.google/subscriptions/>
-   le résultat comporte des erreurs :
    -   des références n'ont pas été trouvées
-   des actions supplémentaires sont nécessaires
    -   cartographier la photo pour sélectionner une référence en cliquant sur un livre
    -   intégration du code dans Freloche

#### cv-book-svg : Make your bookshelf clickable

Use computer vision to generate an SVG that you can overlay onto a photo of your bookshelf that lets you click on each book to find out more information.

-   pour plus de détails et le processus d'installation cf. <https://github.com/capjamesg/cv-book-svg>

-   lancement de la commande avec le lien vers la photo et le résultat

``` sh
cd cv-book-svg
python3 grounded.py --image=/Users/samszo/Sites/freloche/files/Photos-1-001/PXL_20250225_074724229.jpg --output=annotation1.html
```

-   on obtient le document : [freloche/annotation1.html](freloche/annotation1.html)

##### résultats

-   le processus est payant : 0,07 \$ / image <https://platform.openai.com/settings/organization/usage> Autres coûts : <https://platform.openai.com/docs/pricing>
-   le résultat comporte des erreurs :
    -   des livres ne sont pas cartographiés,
    -   des références n'ont pas été trouvées,
    -   des références sont fausses
-   des actions supplémentaires sont nécessaires
    -   intégration du code dans Freloche

### Utilisation d'AnythingLLM

AnythingLLM est une plateforme qui permet de déployer et d'exploiter des modèles de langage (LLMs) de manière flexible et personnalisée. Elle offre des outils pour intégrer des modèles de langage dans des applications spécifiques, tout en permettant une gestion simplifiée des données et des interactions.

### Fonctionnalités principales d'AnythingLLM :

1.  **Déploiement local ou cloud** : Vous pouvez exécuter des modèles localement ou les héberger dans le cloud selon vos besoins.
2.  **Personnalisation des modèles** : Ajustez les modèles pour répondre à des cas d'utilisation spécifiques en utilisant des données personnalisées.
3.  **Gestion des données** : Intégrez et organisez vos données pour optimiser les performances des modèles.
4.  **Interface utilisateur conviviale** : Fournit une interface simple pour interagir avec les modèles et configurer les paramètres.
5.  **Compatibilité avec plusieurs modèles** : Supporte différents modèles de langage, qu'ils soient open source ou propriétaires.

### Cas d'utilisation d'AnythingLLM :

-   **Recherche et analyse** : Exploitez les capacités des LLMs pour extraire des informations pertinentes à partir de grandes quantités de données.
-   **Automatisation des tâches** : Automatisez des processus répétitifs ou complexes grâce à des modèles de langage.
-   **Applications conversationnelles** : Créez des chatbots ou des assistants virtuels pour répondre aux besoins des utilisateurs.
-   **Personnalisation des réponses** : Adaptez les réponses des modèles en fonction du contexte ou des préférences des utilisateurs.

Pour plus d'informations, consultez la documentation officielle : [AnythingLLM GitHub](https://github.com/Mintplex-Labs/anything-llm).

Pour installer l'application sur votre machine : - Pour une application autonome : <https://anythingllm.com/desktop> - Pour une conteneur Docker : <https://hub.docker.com/r/mintplexlabs/anythingllm>

#### Exemple d'utilisation : chatbot avec RAG

AnythingLLM permet de gérer facilement l'ajout de documents pour qu'ils soient pris en compte dans des conversations avec les agents en utilisant des techniques de RAG.

##### Qu'est-ce que le RAG ?

RAG (Retrieval-Augmented Generation) est une technique qui combine les capacités des modèles de langage (LLMs) avec des systèmes de récupération d'informations. L'objectif est d'améliorer la pertinence et la précision des réponses générées par les modèles en s'appuyant sur des données externes.

Pour une veille sur la RAG : <https://www.diigo.com/user/luckysemiosis?query=RAG>

##### Fonctionnement du RAG :

1.  **Récupération d'informations** : Le système interroge une base de données ou un ensemble de documents pour extraire les informations les plus pertinentes en fonction de la requête de l'utilisateur.
2.  **Génération augmentée** : Les informations récupérées sont ensuite utilisées comme contexte pour guider le modèle de langage dans la génération de réponses.

##### Avantages du RAG :

-   **Précision accrue** : En s'appuyant sur des données spécifiques, le modèle peut fournir des réponses plus précises et adaptées.
-   **Réduction des hallucinations** : Le modèle est moins susceptible de générer des informations incorrectes ou inventées.
-   **Personnalisation** : Permet d'adapter les réponses en fonction d'un domaine ou d'un corpus spécifique.

##### Cas d'utilisation :

-   **Recherche documentaire** : Extraction d'informations pertinentes à partir de grandes bases de données.
-   **Assistants virtuels** : Fournir des réponses précises basées sur des documents internes ou des FAQ.
-   **Applications éducatives** : Aider les étudiants ou chercheurs à trouver des informations spécifiques dans des corpus académiques.

En résumé, le RAG est une approche puissante pour combiner les forces des modèles de langage et des systèmes de récupération d'informations, offrant des réponses plus fiables et contextuelles.

##### Faire du RAG avec AnythingLLM

{{< video https://youtu.be/ojkJA3ztnZI >}}

##### Ajouter manuellement des documents

{{< video https://youtu.be/eVBu8hoOiFU >}}

##### Ajouter des documents à partir d'une base de données

Cet exemple est lié au projet de recherche ExploDeleuze : Explorer les cours de Deleuze avec l’IA.

-   Les objectifs de ce projet sont multiples :
    -   Concevoir, développer et tester un dispositif numérique de transcription automatique des collections sonores
    -   Concevoir, développer et tester des applications Web qui utilisent ces transcriptions
    -   Transcrire les cours de Gilles Deleuze disponibles dans Gallica comme preuve de concept
    -   Préparer un projet de plus grande ampleur (ANR, Europe…)

Pour plus d'informations : [https://docs.google.com/document/d/1uqB_7DApJItX4Jonmr8JSefgm2tLvlMlyhh4SnsrtqQ/edit?usp=sharing](projet%20présenté%20à%20la%20BNF).

###### Processus d'ajout de document

![Diagramme de Flux](/mermaid/algoAddDocToAnythyngLLM.png)

###### Utilisation du RAG dans une application tierce

{{< video https://youtu.be/LLgpSsHHCXY >}}


## Bilans

L'usage de l'IA prends beaucoup de temps pour :
- la veille nécessaire pour trouver les bons modèles, les bons outils
- pour *bricoler* une solution en lien avec un projet

Le passage par des IA de plateforme (ChatGPT, Gemini...) raccourci le temps en échange d'argent.

Dans le cas, d'un usage lié à la recherche et l'enseignant, ne devons-nous pas transformer le slogan : "Le temps c'est de l'argent" en "Le temps c'est de la connaissance" et par ce choix, mettre de coté les IA de plateforme au profit des IA bricolées localement même si cela prend plus de temps, même si l'efficacité est moins spectaculaire ?
Quels pouvoir souhaitons-nous développer ?

