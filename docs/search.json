[
  {
    "objectID": "arcanes2023.html",
    "href": "arcanes2023.html",
    "title": "Arcanes 2023",
    "section": "",
    "text": "Les 29, 30 novembre et 1er décembre au carrefour des arts et des sciences à l’Université de Montréal.\n\n\n\n\nVoir en plein écran\n\n\n\n\nFace à la complexité des IAs génératives tant du point de vue des technologies qu’elles utilisent Legoux (2023) que des discours qui portent sur elles [Bachimont (2020); Citton, Lechner, and Anthony (2023); Ertzscheid (2023); Masure (2023); Mineur (2023); veille critique IA], il est difficile de discerner, de raisonner et d’agir avec ces écosystèmes numériques.\nPour aider à une meilleure compréhension de ces phénomènes, nous proposons une méthode d’analyse de ces écosystèmes qui donnent aux chercheurs les moyens de construire des points de vue spécifiques, de les partager avec d’autres et de voir leurs évolutions. Cette méthode s’appuie sur une modélisation onto-éthique des existences informationnelles (Szoniecky 2019, 2020, 2023) qui peuplent ces environnements. Nous nous basons sur cinq principes théoriques :\n\nles connaissances se produisent suivant un cycle continu de sémioses (µ, Edeline, and Klinkenberg 2015) dans le monde physique et dans le monde de la pensée (Descola 2005).\nl’analogie est le « moteur » (Hofstadter and Sander 2013) relie le discernement et l’action en gardant le souvenir de cette relation qui devient à force de répétition : une manière d’être (Latour 2012)\nles souvenirs prennent la forme d’un « pli » (Deleuze 1988) à la manière de deux miroirs qui plient la lumière en se reflétant l’un dans l’autre à l’infini.\nentre discerner et agir, intuition et expression, une « pulsation existentielle » génère une « raison trajective » (Berque 2009)\nles pliages et leurs capacités à se faire, se défaire, se bloquer dépendent du degré de flexibilité cognitive (Clément 2021).\n\nNous illustrerons cette méthode à partir de cartographies des connaissances récoltées dans le projet Arcanes.\n\n\n\nAprès des recherches en histoire de l’art (1995 DEA sur John Cage) et une formation autodidacte aux développements numériques, Samuel Szoniecky suit une carrière d’ingénieur informatique pour des grands comptes, puis de chef de projet et de créateur d’entreprise. Depuis 2006, il oriente son travail vers la recherche et l’enseignement à l’université Paris 8 dans le laboratoire Paragraphe où en 2013 il devient maître de conférences en sciences de l’information et de la communication. Il explore des méthodes de design des connaissances pour le développement d’une intelligence collective centrée sur la stimulation, l’expression et le partage des intelligences individuelles. Plus de détails"
  },
  {
    "objectID": "arcanes2023.html#être-ou-ne-pas-être-trompé-interpréter-les-pouvoirs-des-ias-génératives",
    "href": "arcanes2023.html#être-ou-ne-pas-être-trompé-interpréter-les-pouvoirs-des-ias-génératives",
    "title": "Arcanes 2023",
    "section": "",
    "text": "Voir en plein écran\n\n\n\n\nFace à la complexité des IAs génératives tant du point de vue des technologies qu’elles utilisent Legoux (2023) que des discours qui portent sur elles [Bachimont (2020); Citton, Lechner, and Anthony (2023); Ertzscheid (2023); Masure (2023); Mineur (2023); veille critique IA], il est difficile de discerner, de raisonner et d’agir avec ces écosystèmes numériques.\nPour aider à une meilleure compréhension de ces phénomènes, nous proposons une méthode d’analyse de ces écosystèmes qui donnent aux chercheurs les moyens de construire des points de vue spécifiques, de les partager avec d’autres et de voir leurs évolutions. Cette méthode s’appuie sur une modélisation onto-éthique des existences informationnelles (Szoniecky 2019, 2020, 2023) qui peuplent ces environnements. Nous nous basons sur cinq principes théoriques :\n\nles connaissances se produisent suivant un cycle continu de sémioses (µ, Edeline, and Klinkenberg 2015) dans le monde physique et dans le monde de la pensée (Descola 2005).\nl’analogie est le « moteur » (Hofstadter and Sander 2013) relie le discernement et l’action en gardant le souvenir de cette relation qui devient à force de répétition : une manière d’être (Latour 2012)\nles souvenirs prennent la forme d’un « pli » (Deleuze 1988) à la manière de deux miroirs qui plient la lumière en se reflétant l’un dans l’autre à l’infini.\nentre discerner et agir, intuition et expression, une « pulsation existentielle » génère une « raison trajective » (Berque 2009)\nles pliages et leurs capacités à se faire, se défaire, se bloquer dépendent du degré de flexibilité cognitive (Clément 2021).\n\nNous illustrerons cette méthode à partir de cartographies des connaissances récoltées dans le projet Arcanes.\n\n\n\nAprès des recherches en histoire de l’art (1995 DEA sur John Cage) et une formation autodidacte aux développements numériques, Samuel Szoniecky suit une carrière d’ingénieur informatique pour des grands comptes, puis de chef de projet et de créateur d’entreprise. Depuis 2006, il oriente son travail vers la recherche et l’enseignement à l’université Paris 8 dans le laboratoire Paragraphe où en 2013 il devient maître de conférences en sciences de l’information et de la communication. Il explore des méthodes de design des connaissances pour le développement d’une intelligence collective centrée sur la stimulation, l’expression et le partage des intelligences individuelles. Plus de détails"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Samszo ConfErrance",
    "section": "",
    "text": "Cette page liste les supports de présentation des conférences données par Samuel Szoniecky.\n\n2022 – 01Design12 - Ateliers de design non intentionel\n01Design8\nAAQ_2021\nacfas_2019\nacfas_2021\nadacemu\naliento_2016\narcanes_2021\narcanes_2023\narchives_savoirs\naudition_mcf\nautomatismes_intuitions\nCIBAHN_2016\ncours_semiologie\ncours_systeme-information-programation-internet\ncours_websemantique\nDes générateurs chaotiques aux IA génératives\ndigital_intelligence\necoinfo\nENSSIB_19\nfrontieres_2022\nfrontieres\nH2PTM_19\nH2PTM_21\nHumanAtHome\nHumanAtHome2018\nhyperurbain5\nIAVS-AISV_12\nIAVS-AISV_23\nintelligence_vegetale\niotLabs_2018\nishsl9\niskoMagreb_2015\nje-creationParis8\nMIND_2020\nNDIDO2017\nontostats_2019\nParagraphe_2022\npatrimoine\nPEPE_2019\nrecommandations\nseminaireEHESS_2015\nseminaireFP_2013\nsoftware_digital-humanitiesII\nSoutenance d’HDR\nsqet_2019\nValPedArNum\nvies_artificielles"
  },
  {
    "objectID": "je-CreationParis8.html",
    "href": "je-CreationParis8.html",
    "title": "Journée d’étude La création à Paris 8, pédagogique, artistique et scientifique",
    "section": "",
    "text": "Page Web de l’événement\n\n\n13h-15h Université Paris 8 : Amphi MR002.\nModérateur : Arnaud Regnauld, vice-président de la Commission Recherche Discutants : - Patrick Mollaret (Pr, Psychologie), - Marie Preston (MCF, Arts plastiques), - Lionel Ruffel (Pr, Création littéraire), - Cécile Sorin (Pr, Cinéma), - Samuel Szoniecky (MCF, Humanités numériques)\n\n\n\n\n\nVoir en plein écran\n\n\n\n\nDans cette présentation, nous explorons les questions des écritures génératives suivant une approche écologique inspirée par Felix Guattari (Guattari 1992). Face à la complexité des IAs génératives tant du point de vue des technologies qu’elles utilisent (legoux2023?) que des discours qui portent sur elles [(bachimont2020?); (citton2023?); (ertzscheid2023?); (masure2023?); (mineur2023?); veille critique IA], il est difficile de discerner, de raisonner et d’agir avec ces écosystèmes numériques.\nPour aider à une meilleure compréhension de ces phénomènes, nous proposons une méthode d’analyse de ces écosystèmes qui donnent aux chercheurs les moyens de construire des points de vue spécifiques, de les partager avec d’autres et de voir leurs évolutions. Cette méthode s’appuie sur une modélisation onto-éthique des existences informationnelles (szoniecky2019?; szoniecky2020?; szoniecky2023?) qui peuplent ces environnements. Nous nous basons sur cinq principes théoriques :\n\nles connaissances se produisent suivant un cycle continu de sémioses (µ2015?) dans le monde physique et dans le monde de la pensée (descola2005?).\nl’analogie est le « moteur » (hofstadter2013?) relie le discernement et l’action en gardant le souvenir de cette relation qui devient à force de répétition : une manière d’être (latour2012?)\nles souvenirs prennent la forme d’un « pli » (deleuze1988?) à la manière de deux miroirs qui plient la lumière en se reflétant l’un dans l’autre à l’infini.\nentre discerner et agir, intuition et expression, une « pulsation existentielle » génère une « raison trajective » (berque2009?)\nles pliages et leurs capacités à se faire, se défaire, se bloquer dépendent du degré de flexibilité cognitive (clément2021?).\n\nNous illustrerons cette méthode à partir de cartographies des connaissances récoltées dans le projet Arcanes.\n\n\n\nAprès des recherches en histoire de l’art (1995 DEA sur John Cage) et une formation autodidacte aux développements numériques, Samuel Szoniecky suit une carrière d’ingénieur informatique pour des grands comptes, puis de chef de projet et de créateur d’entreprise. Depuis 2006, il oriente son travail vers la recherche et l’enseignement à l’université Paris 8 dans le laboratoire Paragraphe où en 2013 il devient maître de conférences en sciences de l’information et de la communication. Il explore des méthodes de design des connaissances pour le développement d’une intelligence collective centrée sur la stimulation, l’expression et le partage des intelligences individuelles. Plus de détails"
  },
  {
    "objectID": "je-CreationParis8.html#forum-2-création-et-recherche---amphi-mr002",
    "href": "je-CreationParis8.html#forum-2-création-et-recherche---amphi-mr002",
    "title": "Journée d’étude La création à Paris 8, pédagogique, artistique et scientifique",
    "section": "",
    "text": "13h-15h Université Paris 8 : Amphi MR002.\nModérateur : Arnaud Regnauld, vice-président de la Commission Recherche Discutants : - Patrick Mollaret (Pr, Psychologie), - Marie Preston (MCF, Arts plastiques), - Lionel Ruffel (Pr, Création littéraire), - Cécile Sorin (Pr, Cinéma), - Samuel Szoniecky (MCF, Humanités numériques)\n\n\n\n\n\nVoir en plein écran\n\n\n\n\nDans cette présentation, nous explorons les questions des écritures génératives suivant une approche écologique inspirée par Felix Guattari (Guattari 1992). Face à la complexité des IAs génératives tant du point de vue des technologies qu’elles utilisent (legoux2023?) que des discours qui portent sur elles [(bachimont2020?); (citton2023?); (ertzscheid2023?); (masure2023?); (mineur2023?); veille critique IA], il est difficile de discerner, de raisonner et d’agir avec ces écosystèmes numériques.\nPour aider à une meilleure compréhension de ces phénomènes, nous proposons une méthode d’analyse de ces écosystèmes qui donnent aux chercheurs les moyens de construire des points de vue spécifiques, de les partager avec d’autres et de voir leurs évolutions. Cette méthode s’appuie sur une modélisation onto-éthique des existences informationnelles (szoniecky2019?; szoniecky2020?; szoniecky2023?) qui peuplent ces environnements. Nous nous basons sur cinq principes théoriques :\n\nles connaissances se produisent suivant un cycle continu de sémioses (µ2015?) dans le monde physique et dans le monde de la pensée (descola2005?).\nl’analogie est le « moteur » (hofstadter2013?) relie le discernement et l’action en gardant le souvenir de cette relation qui devient à force de répétition : une manière d’être (latour2012?)\nles souvenirs prennent la forme d’un « pli » (deleuze1988?) à la manière de deux miroirs qui plient la lumière en se reflétant l’un dans l’autre à l’infini.\nentre discerner et agir, intuition et expression, une « pulsation existentielle » génère une « raison trajective » (berque2009?)\nles pliages et leurs capacités à se faire, se défaire, se bloquer dépendent du degré de flexibilité cognitive (clément2021?).\n\nNous illustrerons cette méthode à partir de cartographies des connaissances récoltées dans le projet Arcanes.\n\n\n\nAprès des recherches en histoire de l’art (1995 DEA sur John Cage) et une formation autodidacte aux développements numériques, Samuel Szoniecky suit une carrière d’ingénieur informatique pour des grands comptes, puis de chef de projet et de créateur d’entreprise. Depuis 2006, il oriente son travail vers la recherche et l’enseignement à l’université Paris 8 dans le laboratoire Paragraphe où en 2013 il devient maître de conférences en sciences de l’information et de la communication. Il explore des méthodes de design des connaissances pour le développement d’une intelligence collective centrée sur la stimulation, l’expression et le partage des intelligences individuelles. Plus de détails"
  },
  {
    "objectID": "balpe2025.html",
    "href": "balpe2025.html",
    "title": "Des générateurs chaotiques aux IA génératives",
    "section": "",
    "text": "Colloque international 12-13 juin 2025 - Université Paris 8, Campus Condorcet\n\n\n\n\nVoir en plein écran\n\n\n\n\nIl y a 30 ans presque jour pour jour, j’ai encontré Jean-Pierre Balpe à Paris dans un café de la rue Saint Denis pour lui présenter mon générateur automatique de textes philosophiques conçu avec Hypercard et inspiré par John Cage, Michel Foucault et les théories du chaos. En cet été 1995, mon ambition était de faire une thèse pour expérimenter les usages des ordinateurs dans les sciences humaines, ce que Jean-Pierre avait défini à l’époque comme une recherche sur : “les analyseurs autonomes de données pour la création d’hypertextes adaptatifs”.\n10 ans plus tard, je retrouve Jean-Pierre à la Maison Populaire de Montreuil pour un atelier de “Création d’un roman génératif nommé Fiction (fictions)” ou nous expérimentons des fictions générées par le flux des webcams et représentées sous la forme de fullerènes. C’est l’occasion pour moi de renouer avec le département Hypermédia et le laboratoire Paragraphe, de commencer une nouvelle carrière à l’université et de collaborer avec Jean-Pierre à la conception des nouvelles versions de ses générateurs automatiques de textes et à l’expérimentations de nouveaux usages…\nAujourd’hui, au moment où l’Université Paris 8 exprime de plus en plus fortement sa volonté d’être une “université des créations”, il nous semble important en tant que participant à ces expériences “balpiennes”, d’enraciner cette politique institutionnelle dans l’histoire de ceux qui ont habité ce lieu. Jean-Pierre Balpe est sans doute un des acteurs importants de cette manière d’être universitaire qui a fait émerger des enseignants - chercheurs – créateurs. Nous sommes nombreux à nous frayer un chemin dans les dédales de nos institutions et de nos pensées en suivant les traces que Jean-Pierre nous a laissées, nous a appris à voir et entretenir. Comment retracer ces frayages et analyser l’influence de Jean-Pierre sur eux ?\nNous proposons ici une archéologie des savoirs stimulés par nos rapports avec Jean-Pierre Balpe. Notre objectif n’est pas celui d’un catalogage exhaustif des connaissances, nous souhaitons plutôt montrer quelques fragments de cette histoire qui nous semble particulièrement important. Pour ce faire, nous utiliserons la méthode de modélisation des existences informationnelles que nous avons conçu pour quantifier la complexité d’un évenement et analyser les évolutions des pouvoirs de discernement, de raisonnement et d’agir.\n\n\n\nAprès des recherches en histoire de l’art (1995 DEA sur John Cage) et une formation autodidacte aux développements numériques, Samuel Szoniecky suit une carrière d’ingénieur informatique pour des grands comptes, puis de chef de projet et de créateur d’entreprise. Depuis 2006, il oriente son travail vers la recherche et l’enseignement à l’université Paris 8 dans le laboratoire Paragraphe où en 2013 il devient maître de conférences en sciences de l’information et de la communication. Il explore des méthodes de design des connaissances pour le développement d’une intelligence collective centrée sur la stimulation, l’expression et le partage des intelligences individuelles. Plus de détails"
  },
  {
    "objectID": "balpe2025.html#des-générateurs-chaotiques-aux-ia-génératives",
    "href": "balpe2025.html#des-générateurs-chaotiques-aux-ia-génératives",
    "title": "Des générateurs chaotiques aux IA génératives",
    "section": "Des générateurs chaotiques aux IA génératives",
    "text": "Des générateurs chaotiques aux IA génératives\n\nPrésentation\nVoir en plein écran\n\n\n\nRésumé\nIl y a 30 ans presque jour pour jour, j’ai encontré Jean-Pierre Balpe à Paris dans un café de la rue Saint Denis pour lui présenter mon générateur automatique de textes philosophiques conçu avec Hypercard et inspiré par John Cage, Michel Foucault et les théories du chaos. En cet été 1995, mon ambition était de faire une thèse pour expérimenter les usages des ordinateurs dans les sciences humaines, ce que Jean-Pierre avait défini à l’époque comme une recherche sur : “les analyseurs autonomes de données pour la création d’hypertextes adaptatifs”.\n10 ans plus tard, je retrouve Jean-Pierre à la Maison Populaire de Montreuil pour un atelier de “Création d’un roman génératif nommé Fiction (fictions)” ou nous expérimentons des fictions générées par le flux des webcams et représentées sous la forme de fullerènes. C’est l’occasion pour moi de renouer avec le département Hypermédia et le laboratoire Paragraphe, de commencer une nouvelle carrière à l’université et de collaborer avec Jean-Pierre à la conception des nouvelles versions de ses générateurs automatiques de textes et à l’expérimentations de nouveaux usages…\nAujourd’hui, au moment où l’Université Paris 8 exprime de plus en plus fortement sa volonté d’être une “université des créations”, il nous semble important en tant que participant à ces expériences “balpiennes”, d’enraciner cette politique institutionnelle dans l’histoire de ceux qui ont habité ce lieu. Jean-Pierre Balpe est sans doute un des acteurs importants de cette manière d’être universitaire qui a fait émerger des enseignants - chercheurs – créateurs. Nous sommes nombreux à nous frayer un chemin dans les dédales de nos institutions et de nos pensées en suivant les traces que Jean-Pierre nous a laissées, nous a appris à voir et entretenir. Comment retracer ces frayages et analyser l’influence de Jean-Pierre sur eux ?\nNous proposons ici une archéologie des savoirs stimulés par nos rapports avec Jean-Pierre Balpe. Notre objectif n’est pas celui d’un catalogage exhaustif des connaissances, nous souhaitons plutôt montrer quelques fragments de cette histoire qui nous semble particulièrement important. Pour ce faire, nous utiliserons la méthode de modélisation des existences informationnelles que nous avons conçu pour quantifier la complexité d’un évenement et analyser les évolutions des pouvoirs de discernement, de raisonnement et d’agir.\n\n\nBiographie\nAprès des recherches en histoire de l’art (1995 DEA sur John Cage) et une formation autodidacte aux développements numériques, Samuel Szoniecky suit une carrière d’ingénieur informatique pour des grands comptes, puis de chef de projet et de créateur d’entreprise. Depuis 2006, il oriente son travail vers la recherche et l’enseignement à l’université Paris 8 dans le laboratoire Paragraphe où en 2013 il devient maître de conférences en sciences de l’information et de la communication. Il explore des méthodes de design des connaissances pour le développement d’une intelligence collective centrée sur la stimulation, l’expression et le partage des intelligences individuelles. Plus de détails"
  },
  {
    "objectID": "hdrSamSzo.html",
    "href": "hdrSamSzo.html",
    "title": "Dossier d’Habilitation à Diriger des Recherches en Sciences de l’Information et de la Communication.",
    "section": "",
    "text": "{style=“height:80px;”"
  },
  {
    "objectID": "hdrSamSzo.html#samuel-szoniecky",
    "href": "hdrSamSzo.html#samuel-szoniecky",
    "title": "Dossier d’Habilitation à Diriger des Recherches En Sciences de l’information et de la communication.",
    "section": "Samuel Szoniecky",
    "text": "Samuel Szoniecky"
  },
  {
    "objectID": "hdrSamSzo.html#synthèse-du-dossier-hdr-de-samuel-szoniecky",
    "href": "hdrSamSzo.html#synthèse-du-dossier-hdr-de-samuel-szoniecky",
    "title": "Dossier d’Habilitation à Diriger des Recherches En Sciences de l’information et de la communication.",
    "section": "Synthèse du dossier HDR de Samuel Szoniecky",
    "text": "Synthèse du dossier HDR de Samuel Szoniecky\n\nVolume 1. Curriculum Vitae\nVoir en ligne le CV complet\nLe curriculum vitae de 78 pages est organisé en deux parties :\n\nPartie 1 : une synthèse de mes activités scientifiques, pédagogiques et administratives\nPartie 2 : une présentation détaillée de l’ensemble de mes activités.\nCette présentation détaillée explicite les aspects suivants :\n\nune présentation de ma carrière,\nmes diplômes académiques,\nmes responsabilités administratives,\nmon parcours professionnel dans les activités d’enseignement,\nmon parcours professionnel dans les activités de recherche,\nmes publications productions scientifiques et leurs références sur HAL France\n\n\nDepuis mon recrutement, ma carrière se déroule :\n\nPour l’aspect enseignement\nJe donne principalement des cours au Département Humanités Numériques (anciennement Hypermedias) de l’Université Paris 8. Les enseignements que j’ai donnés se développent suivant trois axes complémentaires :\n\ntechnique,\nconceptuel,\ncollaboratif.\n\n\n\n\n\n\n\n\nMémoires de Master encadrés (M1 et M2)\n31\n\n\nStages encadrés dans le laboratoire Paragraphe\n11\n\n\nCours\n20\n\n\nEtablissement d’enseignement\n7\n\n\nParcours d’enseignement\n14\n\n\nHeure de cours à l’université depuis 2012\n+3 300\n\n\nProduction de documents pédagogiques\n35\n\n\nConception dispositifs pédagogiques innovants\n18\n\n\n\n\n\nPour l’aspect administratif\nMon implication dans les instances de l’université Paris 8 en tant que :\n\nmembre du Conseil Documentaire du SCD,\ndu conseil pédagogique de l’UFR STN\nde la commission de spécialistes en science de l’information et de la communication\n\nme donne une bonne connaissance des rouages nécessaires et des difficultés qu’il faut surmonter pour que les activités de recherche et la vie des institutions se développent. Grâce à ces activités, j’ai eu la chance de dialoguer avec de très nombreux chercheurs dont la liste complète serait trop longue à faire figurer ici mais que je remercie vivement pour ces conversations où l’échange de points de vue parfois très différents donnent à la recherche un goût à la fois subtile, surprenant et aventureux.\n\n\n\n\n\n\n\nPrésent - 2023\nDirecteur du département Humanités Numériques, Université Paris 8\n\n\nPrésent - 2023\nMembre élu du conseil de l’UFR STN\n\n\nPrésent - 2020\nMembre du conseil pédagogique de l’UFR STN Paris 8\n\n\nPrésent - 2018\nMembre élu de la commission de spécialistes 71e section\n\n\nPrésent - 2018\nMembre de conseil académique de l’EUR ArTec\n\n\nPrésent - 2016\nMembre du conseil documentaire du SCD, Université Paris 8\n\n\nPrésent - 2014\nMembre de comité de sélection pour des postes de MCF en SIC\n9 dont 2 Vice-président\n\n\nPrésent - 2023\nResponsable pédagogique Master 2 ACEHN\n\n\n2023 - 2018\nResponsable pédagogique Master 2 AVUN\n\n\n2019 - 2010\nResponsable pédagogique Licence Pro DWM\n\n\n\n\n\nPour l’aspect recherche\nJe travaille au (laboratoire Paragraphe) (EA 349, Université Paris 8) principalement dans l’axe Dispositifs numériques : production, usages et modélisation communicationnelle (DiNuPUMoC) sous la direction d’Imad Saleh mais avec de nombreuses collaborations avec les autres axes de ce laboratoire notamment Innovation numérique et Intelligence Artificielle (CiTU), Médiations, Pratiques Informationnelles, Patrimoine (MPIP), Apprentissage, développement, cognition (ADC) lors de publications communes ou d’organisation d’évènement scientifiques (séminaire Adacemu, O1 Design, H2ptm…).\nL’atmosphère très fertile au sein de Paragraphe et les relations intenses que ce laboratoire entretient avec la communauté des sciences de l’information et de la communication, a stimulé l’engagement de mes recherches dans de multiples collaborations en France et à l’étranger. Celles-ci m’ont permis de découvrir des milieux et des pratiques très diverses, par exemple : avec des institutions prestigieuses comme la Bibliothèque Nationale de France, les Archives Nationales ou l’INA, avec des programmes de recherche ANR comme Biolographes ou Aliento, avec des projets de recherches internationaux comme Arcanes, avec des groupes de recherches comme GENIC ou MANEP, avec des enjeux sociétaux importants comme celui de l’accessibilité, de l’écologie ou de l’éthique.\nLa participation dès l’origine à trois Projets d’Investissement d’Avenir (PIA) que sont le laboratoire d’excellence H2H, l’IDEFI CréaTIC et l’EUR ArTec, m’a donné la chance de découvrir des projets importants tout à la fois en terme de gouvernance de la recherche que de possibilité d’expérimentation.\n\n\n\n\n\n\n\nArticle dans une revue\nIndividuel : 2\nCollectif : 8\n\n\nCommunication dans un congrès\nIndividuel : 33\nCollectif : 17\n\n\nProceedings - Recueil des communications\nCollectif : 2\n\n\nNo spécial de revue\nCollectif : 1\n\n\nOuvrage\nIndividuel : 2\nCollectif : 5\n\n\nChapitre d’ouvrage\nIndividuel : 6\nCollectif : 5\n\n\nLogiciel\n92\n\n\n\n\n\n\nVolume 2. Note de synthèse\nVoir en ligne la note de synthèse\nCette note de synthèse de 202 pages intitulé « Modéliser les écosystèmes de connaissances » présente la démarche autoréflexive que j’ai menée dans ce travail. Elle commence par une description de l’état actuel de mes recherches et a pour ambition un dévoilement sincère des limites de ma pensée sous la forme de cartographies qui tracent les frontières numériques (Saleh, Szoniecky, and Ghenima 2024) de ce qui est important pour moi aujourd’hui, c’est-à-dire la valeur des rapports que j’entretiens entre ma subjectivité (Guattari 1989) et mon objectivité (Badiou 2018) et qui forme mon milieu de connaissances (Berque 2009).\nExplorer c’est à la fois cartographier, formaliser et guider. Tout commence par la découverte d’un lieu, par l’expérience d’un espace dont on va ensuite décrire les impressions qu’il produit suivant des règles convenues pour que d’autres puissent les retrouver après soi-même. Les espaces que nous décrivons sont des milieux, c’est-à-dire un tissu relationnel au sein duquel les connaissances existent, et sans lequel elles n’existeraient pas. Ce sont des espaces vivants qui évoluent sans cesse et nous transforment à chaque interaction que nous entretenons avec eux (Aït-Touati, Arènes, and Grégoire 2019). Suivant le principe d’énaction (Maturana and Varela 1994), le couplage entre l’espace et l’auteur de sa description transforme à la fois l’espace et l’auteur.\nExplorer c’est se connaître soi-même en modélisant le milieu de ses expériences et en réfléchissant aux transformations que cela produit.\nCe volume de mon HDR présente un processus d’exploration qui commence par une première partie qui décrit les étapes de mon parcours intellectuel à travers mes frayages intellectuels (Citton 2010) qui débutent avec l’histoire de l’art puis s’ancre dans les sciences de l’information et de la communication pour développer un projet de design des connaissances qui mène à une théorisation des écosystèmes de connaissances et finalement à la mise en pratique d’une méthode de modélisation et d’analyse de l’information et de la communication.\nCe chapitre présente :\n\nmes parcours initiaux\nmon parcours en Sciences de l’information et de la communication\nma méthode pour créer un écosystème de connaissances\nles données de mon écosystème de connaissances\nles personnes de mon écosystème de connaissances\n\nNous voyons ensuite dans une deuxième partie consacrée à l’exploration des écosystèmes de connaissances les résultats de mes recherches qui m’ont conduit à définir des principes à la fois théoriques et pratiques.\nLa troisième partie de ce volume est consacrée aux perspectives scientifiques que nous développons en suivant quatre échelles d’exploration :\n\néchelle locale : produire une expression matérielle cohérente\néchelle sociale : la communauté des enseignants chercheurs\néchelle conceptuelle : théoriser la modélisation des connaissances\néchelle globale : technologies intellectives\n\nNous exposons les explorations de ces échelles en suivant six axes d’expérimentation :\n\nFrontières numériques\nl’internet des objets,\nles écritures génératives\nle design des connaissances\nl’éthique de la discussion pour l’intelligence collective,\nles puissances existentielles.\n\nEnfin nous concluons ce volume par une synthèse de nos propos et la présentation des annexes et des références utilisées.\n\n\nVolume 3. Sélection des travaux\nCe volume de 201 pages présente une sélection de mes travaux :\n\nFrontières numériques 2023\nConception d’un crible pour mesurer collectivement les impacts écologiques de l’activité\nDesign de connaissances dans l’Internet des Objets : Blockchain et réfrigérateur connecté\nEspace liminaire de l’authenticité : Une démarche d’humanités numériques\nMétamorphoses et hybridations d’une archive numérique pour sa valorisation\nVers des écosystèmes de connaissances\nJeux d’interprétations collectives pour cartographier les influences sapientielles\nÉcosystème de connaissances, méthode de modélisation et d’analyse de l’information et de la communication\nGénérateur hypertextuel pour l’interprétation des médias sociaux dans une topologie sémantique"
  },
  {
    "objectID": "acfas2025_creationHN.html",
    "href": "acfas2025_creationHN.html",
    "title": "Balpe 2025",
    "section": "",
    "text": "École de technologie supérieure (ÉTS) et Université Concordia Montréal, jeudi 8 et vendredi 9 mai 2025\n\n\n\n\nLes controverses des années 60 entre Cage et Boulez sur l’usage des processus aléatoires dans la création musicale sont toujours pertinentes pour comprendre les pratiques créatives du numériques. Boulez prônait un “hasard dirigé” pour maîtriser l’œuvre, tandis que Cage utilisait l’aléatoire pour libérer la création des contraintes de l’ego. Ces approches opposées, se retrouvent dans les débats actuels sur les IA symbolique et connexionniste. D’un côté, une intelligence artificielle connexionniste qui utilise l’apprentissage machine pour créer des modèles à partir de grandes quantités de données. De l’autre, une approche symbolique qui modélise des espaces sémantiques pensés par des humains pour contraindre les choix de la machine. Nous explorerons comment ces débats nous aide à comprendre les écosystèmes sociaux-numériques développés par les humanités numériques en illustrant nos propos avec deux projets : « Narration générative entre IA symbolique et connexionniste » et « Explorer les cours de Deleuze avec l’IA ».\n\n\n\nAprès des recherches en histoire de l’art (1995 DEA sur John Cage) et une formation autodidacte aux développements numériques, Samuel Szoniecky suit une carrière d’ingénieur informatique pour des grands comptes, puis de chef de projet et de créateur d’entreprise. Depuis 2006, il oriente son travail vers la recherche et l’enseignement à l’université Paris 8 dans le laboratoire Paragraphe où en 2013 il devient maître de conférences en sciences de l’information et de la communication. Il explore des méthodes de design des connaissances pour le développement d’une intelligence collective dans des projets d’Humanités numériques centrés sur la stimulation, l’expression et le partage des intelligences individuelles. Plus de détails"
  },
  {
    "objectID": "acfas2025_creationHN.html#ia-symboliques-et-connexionnistes-dans-le-humanités-numériques-consommation-production-et-création",
    "href": "acfas2025_creationHN.html#ia-symboliques-et-connexionnistes-dans-le-humanités-numériques-consommation-production-et-création",
    "title": "Balpe 2025",
    "section": "",
    "text": "Les controverses des années 60 entre Cage et Boulez sur l’usage des processus aléatoires dans la création musicale sont toujours pertinentes pour comprendre les pratiques créatives du numériques. Boulez prônait un “hasard dirigé” pour maîtriser l’œuvre, tandis que Cage utilisait l’aléatoire pour libérer la création des contraintes de l’ego. Ces approches opposées, se retrouvent dans les débats actuels sur les IA symbolique et connexionniste. D’un côté, une intelligence artificielle connexionniste qui utilise l’apprentissage machine pour créer des modèles à partir de grandes quantités de données. De l’autre, une approche symbolique qui modélise des espaces sémantiques pensés par des humains pour contraindre les choix de la machine. Nous explorerons comment ces débats nous aide à comprendre les écosystèmes sociaux-numériques développés par les humanités numériques en illustrant nos propos avec deux projets : « Narration générative entre IA symbolique et connexionniste » et « Explorer les cours de Deleuze avec l’IA ».\n\n\n\nAprès des recherches en histoire de l’art (1995 DEA sur John Cage) et une formation autodidacte aux développements numériques, Samuel Szoniecky suit une carrière d’ingénieur informatique pour des grands comptes, puis de chef de projet et de créateur d’entreprise. Depuis 2006, il oriente son travail vers la recherche et l’enseignement à l’université Paris 8 dans le laboratoire Paragraphe où en 2013 il devient maître de conférences en sciences de l’information et de la communication. Il explore des méthodes de design des connaissances pour le développement d’une intelligence collective dans des projets d’Humanités numériques centrés sur la stimulation, l’expression et le partage des intelligences individuelles. Plus de détails"
  },
  {
    "objectID": "hdrSamSzo.html#universite-vincennes---saint-denis-paris-8",
    "href": "hdrSamSzo.html#universite-vincennes---saint-denis-paris-8",
    "title": "Dossier d’Habilitation à Diriger des Recherches en Sciences de l’Information et de la Communication.",
    "section": "",
    "text": "|||"
  },
  {
    "objectID": "SOCIN25_propSamSzo.html",
    "href": "SOCIN25_propSamSzo.html",
    "title": "SOCIN’ 25 proposition Samuel Szoniecky",
    "section": "",
    "text": "Congrès annuel de l’Alliance ERUA - SOCIN’25 Du 23 au 26 septembre 2025 Université de Macerata (Italie)\n\n\n\n\nLe centre expérimental de Vincennes est relativement connue et a fait l’objet de publications (Soulié 2012; Merlin et al. 1979; Merlin 1980; Ohayon 2022; Grésillon et al. 2021), d’une thèse (Dormoy-Rajramanan 2014), d’un film documentaire (Sluys et al. 2018), d’une émission de radio (Mauduit, n.d.)… Une fois déménagée à Saint-Denis, ce centre devenu l’Université Paris 8 continue son histoire mais celle-ci est bien moins documentée et a fait l’objet d’une moins grande attention. L’objectif de cette recherche est d’explorer la mémoire des acteurs de ce projet innovant, plus particulièrement, nous nous focalisons sur un aspect particulier de cette université celui de la création numérique (Eymet 2016) qui à travers les disciplines encore non enseignées à l’université dans les années 80 comme l’hypermédia et l’intelligence artificielle, se fraye (Citton 2010) un chemin dans les pratiques universitaires jusqu’aujourd’hui où Paris 8 proclame “les créations” comme moteur de son avenir.\nNous concevons ce projet comme une démarche interdisciplinaire qui vise n’ont pas l’exhaustivité des témoignages, ni un catalogue d’événements dans une chronologie figée mais la conception d’un environnement éditorial qui en stimulant l’expression des points de vues, s’enrichie au fur et à mesure des contributions.\nNous avons montré dans (Szoniecky 2019) comment ce type de démarche éditoriale oscille entre une volonté d’exprimer des faits formellement interopérables pour construire une argumentation logique et celle d’une expression plus intuitives qui stimule une inspiration créative pour une expression plus émotionnelle. Dans le projet qui nous occupe ici, à savoir la cartographie des souvenirs pour une archéologie des créations à Paris 8, nous devons prendre en compte ces deux modes d’éditorialisation puisque la cartographie est un exercice formel et le souvenir une pratique intuitive. Associé ces deux démarches permet tout à la fois de rendre interopérable les contenus édités mais aussi de laisser une grande liberté à l’expression des témoignages.\nUn autre point très important est de mettre la médiation humaine au cœur de cette environnement éditorial. Nous croyons qu’à l’heure de la prolifération des IA, il est fondamental de ne pas les utiliser uniquement pour la production intensive de contenus. Il nous semble que les réflexions autour de la qualité de ce que produit l’IA par exemple en terme de pertinence du propos, de corrections des biais ou de corrélation avec l’expression humaine… sont beaucoup moins importantes que les recherches sur les moyens d’utiliser l’IA pour faire émerger une intelligence collective (Lévy 2011), une éthique de la discussion (Habermas 2013) et des usages écologiquement responsables (Lefevre et al. 2023). Ce qui importe c’est moins la réponse à des impératifs de productivité inhérents à une évaluation quantitative de la recherche plutôt que la construction collective d’enjeux communs dont la complexité nécessite des capacités d’organisation et de calcul auxquelles les IA peuvent sans doute contribuer. Encore faut-il laissé une place importante aux humains pour qu’ils expriment leurs expertises mais aussi leurs questionnements, leurs doutes et leurs peurs. Il nous faut à la fois gagner en efficacité organisationnelle et ne pas perdre la dimension émotionnelle des rapports humains qui est indispensable à une démarche éthique qui prend en compte l’altérité et l’émergence de point de vue différents.\nUne première version de cet environnement éditorial sera testé lors du colloque dédié à l’oeuvre de Jean-Pierre Balpe le 12 et 13 juin 2025 cf. https://balpe2025.sciencesconf.org/. Il se basera sur un dispositif numérique nommé “Freloche” qui met en scène l’analogie du jardin et la chasse aux papillons pour stimuler les réactions mémorielles des participants au colloque avec des images issues de collections numérisées notamment celles de Paris 8 (https://octaviana.fr/). L’objectif est de récolter les commentaires oraux des participants pour initier un dialogue qui prendra ensuite d’autres formes : focus groupe, entretiens individuels… Nous souhaitons expérimenter une nouvelle version de cette environnement lors de la conférence SOCIN 2025 “Rethinking Innovation” pour élargir le réseau des acteurs et les potentialités d’expression d’une mémoire commune."
  },
  {
    "objectID": "SOCIN25_propSamSzo.html#cartographie-des-souvenirs-pour-une-archéologie-des-créations-à-paris-8-conception-dun-environnement-numérique-de-captation-des-souvenirs-et-dexploration-des-récits-mémoriels",
    "href": "SOCIN25_propSamSzo.html#cartographie-des-souvenirs-pour-une-archéologie-des-créations-à-paris-8-conception-dun-environnement-numérique-de-captation-des-souvenirs-et-dexploration-des-récits-mémoriels",
    "title": "SOCIN’ 25 proposition Samuel Szoniecky",
    "section": "",
    "text": "Le centre expérimental de Vincennes est relativement connue et a fait l’objet de publications (Soulié 2012; Merlin et al. 1979; Merlin 1980; Ohayon 2022; Grésillon et al. 2021), d’une thèse (Dormoy-Rajramanan 2014), d’un film documentaire (Sluys et al. 2018), d’une émission de radio (Mauduit, n.d.)… Une fois déménagée à Saint-Denis, ce centre devenu l’Université Paris 8 continue son histoire mais celle-ci est bien moins documentée et a fait l’objet d’une moins grande attention. L’objectif de cette recherche est d’explorer la mémoire des acteurs de ce projet innovant, plus particulièrement, nous nous focalisons sur un aspect particulier de cette université celui de la création numérique (Eymet 2016) qui à travers les disciplines encore non enseignées à l’université dans les années 80 comme l’hypermédia et l’intelligence artificielle, se fraye (Citton 2010) un chemin dans les pratiques universitaires jusqu’aujourd’hui où Paris 8 proclame “les créations” comme moteur de son avenir.\nNous concevons ce projet comme une démarche interdisciplinaire qui vise n’ont pas l’exhaustivité des témoignages, ni un catalogue d’événements dans une chronologie figée mais la conception d’un environnement éditorial qui en stimulant l’expression des points de vues, s’enrichie au fur et à mesure des contributions.\nNous avons montré dans (Szoniecky 2019) comment ce type de démarche éditoriale oscille entre une volonté d’exprimer des faits formellement interopérables pour construire une argumentation logique et celle d’une expression plus intuitives qui stimule une inspiration créative pour une expression plus émotionnelle. Dans le projet qui nous occupe ici, à savoir la cartographie des souvenirs pour une archéologie des créations à Paris 8, nous devons prendre en compte ces deux modes d’éditorialisation puisque la cartographie est un exercice formel et le souvenir une pratique intuitive. Associé ces deux démarches permet tout à la fois de rendre interopérable les contenus édités mais aussi de laisser une grande liberté à l’expression des témoignages.\nUn autre point très important est de mettre la médiation humaine au cœur de cette environnement éditorial. Nous croyons qu’à l’heure de la prolifération des IA, il est fondamental de ne pas les utiliser uniquement pour la production intensive de contenus. Il nous semble que les réflexions autour de la qualité de ce que produit l’IA par exemple en terme de pertinence du propos, de corrections des biais ou de corrélation avec l’expression humaine… sont beaucoup moins importantes que les recherches sur les moyens d’utiliser l’IA pour faire émerger une intelligence collective (Lévy 2011), une éthique de la discussion (Habermas 2013) et des usages écologiquement responsables (Lefevre et al. 2023). Ce qui importe c’est moins la réponse à des impératifs de productivité inhérents à une évaluation quantitative de la recherche plutôt que la construction collective d’enjeux communs dont la complexité nécessite des capacités d’organisation et de calcul auxquelles les IA peuvent sans doute contribuer. Encore faut-il laissé une place importante aux humains pour qu’ils expriment leurs expertises mais aussi leurs questionnements, leurs doutes et leurs peurs. Il nous faut à la fois gagner en efficacité organisationnelle et ne pas perdre la dimension émotionnelle des rapports humains qui est indispensable à une démarche éthique qui prend en compte l’altérité et l’émergence de point de vue différents.\nUne première version de cet environnement éditorial sera testé lors du colloque dédié à l’oeuvre de Jean-Pierre Balpe le 12 et 13 juin 2025 cf. https://balpe2025.sciencesconf.org/. Il se basera sur un dispositif numérique nommé “Freloche” qui met en scène l’analogie du jardin et la chasse aux papillons pour stimuler les réactions mémorielles des participants au colloque avec des images issues de collections numérisées notamment celles de Paris 8 (https://octaviana.fr/). L’objectif est de récolter les commentaires oraux des participants pour initier un dialogue qui prendra ensuite d’autres formes : focus groupe, entretiens individuels… Nous souhaitons expérimenter une nouvelle version de cette environnement lors de la conférence SOCIN 2025 “Rethinking Innovation” pour élargir le réseau des acteurs et les potentialités d’expression d’une mémoire commune."
  },
  {
    "objectID": "tdcw25.html#participants",
    "href": "tdcw25.html#participants",
    "title": "Transnational Digital Creation Workshop 2025",
    "section": "Participants",
    "text": "Participants\n\nLaura Shackelford - lxsgla\nLaura Shackelford is a professor at the Rochester Institute of Technology, specializing in digital humanities and transnational studies. Her work focuses on the intersection of technology, culture, and creative practices.\n\n\nSamuel Szoniecky - samszo\nSamuel Szoniecky is a researcher at the Laboratoire Paragraphe, Université Paris 8. His expertise lies in digital creation, collaborative platforms, and the development of innovative tools for transdisciplinary research.\n\nAli Ech-Chaoui\nAntonin Passemard\nAva Zafari Anaraki\nAyat Chahdi\nBenito Maramaldi\nHortense Chauvet\nNisrine Benkirane\nSidney Grabosky\nRinky Mahajan\nSomiya El Mimouni\n\nPlease send me a short bio and your GitHub login."
  },
  {
    "objectID": "tdcw25.html#planning",
    "href": "tdcw25.html#planning",
    "title": "Transnational Digital Creation Workshop 2025",
    "section": "Planning",
    "text": "Planning\n\nSection 1.3 videoconferences : 2 Mai 2025, Ven. De 16:00 à 17:00\nSection 1.4 videoconference : 16 Mai 2025, Ven. De 16:00 à 17:00\nSection 1.5 Université Paris 8 - A 175 : 19 Mai 2025, Lun. De 10:00 à 16:00\nSection 1.6 Université Paris 8 - A 175 : 20 Mai 2025, Mar. De 10:00 à 16:00\nSection 1.7 Université Paris 8 - A 175 : 21 Mai 2025, Mer. De 10:00 à 16:00\nSection 1.8 Université Paris 8 - A 175 : 22 Mai 2025, Jeu. De 10:00 à 16:00\nSection 1.9 Université Paris 8 - A 175 : 23 Mai 2025, Ven. De 10:00 à 16:00\nSection 1.10 videoconference : 6 Juin 2025, Ven. De 16:00 à 17:00\nSection 1.11 videoconference : 20 Juin 2025, Ven. De 16:00 à 17:00\n\nLink for videoconference : https://univ-paris8.zoom.us/j/98180450564?pwd=m0k66tKFq3J4gNi8iWz7y9wEo6qjMi.1"
  },
  {
    "objectID": "tdcw25.html#sec-session1",
    "href": "tdcw25.html#sec-session1",
    "title": "Transnational Digital Creation Workshop 2025",
    "section": "Session 1",
    "text": "Session 1\n\nLaura Shackelford - Introduction\nView in full screen\nDownload PDF file.\n\n\nSamuel Szoniecky - Generative Digital Interactions\nView in full screen"
  },
  {
    "objectID": "tdcw25.html#sec-session2",
    "href": "tdcw25.html#sec-session2",
    "title": "Transnational Digital Creation Workshop 2025",
    "section": "Session 2",
    "text": "Session 2"
  },
  {
    "objectID": "tdcw25.html#sec-session3",
    "href": "tdcw25.html#sec-session3",
    "title": "Transnational Digital Creation Workshop 2025",
    "section": "Session 3",
    "text": "Session 3\nAnything LLM doc : https://docs.useanything.com/\nTo have models : https://huggingface.co/"
  },
  {
    "objectID": "tdcw25.html#sec-session4",
    "href": "tdcw25.html#sec-session4",
    "title": "Transnational Digital Creation Workshop 2025",
    "section": "Session 4",
    "text": "Session 4"
  },
  {
    "objectID": "tdcw25.html#sec-session5",
    "href": "tdcw25.html#sec-session5",
    "title": "Transnational Digital Creation Workshop 2025",
    "section": "Session 5",
    "text": "Session 5"
  },
  {
    "objectID": "tdcw25.html#sec-session6",
    "href": "tdcw25.html#sec-session6",
    "title": "Transnational Digital Creation Workshop 2025",
    "section": "Session 6",
    "text": "Session 6"
  },
  {
    "objectID": "tdcw25.html#sec-session7",
    "href": "tdcw25.html#sec-session7",
    "title": "Transnational Digital Creation Workshop 2025",
    "section": "Session 7",
    "text": "Session 7"
  },
  {
    "objectID": "tdcw25.html#sec-session8",
    "href": "tdcw25.html#sec-session8",
    "title": "Transnational Digital Creation Workshop 2025",
    "section": "Session 8",
    "text": "Session 8"
  },
  {
    "objectID": "tdcw25.html#sec-session9",
    "href": "tdcw25.html#sec-session9",
    "title": "Transnational Digital Creation Workshop 2025",
    "section": "Session 9",
    "text": "Session 9"
  },
  {
    "objectID": "iaSem1.html#pourquoi-utiliser-ollama",
    "href": "iaSem1.html#pourquoi-utiliser-ollama",
    "title": "Séminaire IA - 1",
    "section": "Pourquoi utiliser Ollama",
    "text": "Pourquoi utiliser Ollama\nOllama permet d’exécuter des modèles d’intelligence artificielle localement sur son ordinateur, sans dépendre de services cloud externes. Cela garantit la confidentialité des données, réduit les coûts liés à l’utilisation de l’IA et offre une grande flexibilité pour tester différents modèles open source. De plus, Ollama facilite l’intégration de l’IA dans des projets personnels ou professionnels grâce à une interface simple et des commandes intuitives.\n\nPour plus de détails :\n\nLes sources : https://github.com/ollama/ollama\nla veille : https://www.diigo.com/user/luckysemiosis?query=ollama"
  },
  {
    "objectID": "iaSem1.html#installation-de-ollama",
    "href": "iaSem1.html#installation-de-ollama",
    "title": "Séminaire IA - 1",
    "section": "Installation de Ollama",
    "text": "Installation de Ollama\n\nInstallation sur votre ordinateur\n\nPour Windows, macOS et Linux\n\nRendez-vous sur la page officielle : https://ollama.com/download\nTéléchargez le programme d’installation adapté à votre système d’exploitation.\nLancez l’installation et suivez les instructions à l’écran.\n\n\n\nInstallation via la ligne de commande (pour les utilisateurs avancés)\n\nmacOS (Homebrew) :\nbrew install ollama\nLinux (script officiel) :\ncurl -fsSL https://ollama.com/install.sh | sh\nWindows : Téléchargez l’installateur depuis le site officiel et exécutez-le.\n\n\n\nTest d’installation\nollama --version\n\n\n\nChargement des modèles\n\nExemple : Pour charger un modèle spécifique, utilisez la commande suivante :\n\nollama pull &lt;nom_du_modèle&gt;\n\nExemple : pour charger le modèle “llama2”\n\nollama pull llama2\n\nListe des modèles disponibles sur votre machine\nollama list\n\n\n\nQuel modèle choisir ?\nPour choisir un modèle Ollama, il est important de prendre en compte les critères suivants :\n\nObjectif du projet : Déterminez si vous avez besoin d’un modèle pour la génération de texte, la classification, la traduction, ou d’autres tâches spécifiques.\nTaille du modèle : Les modèles plus grands, comme LLaMA 2-13B, offrent généralement de meilleures performances, mais nécessitent plus de ressources (mémoire et puissance de calcul). Si vous travaillez sur une machine avec des ressources limitées, privilégiez un modèle plus léger.\nDonnées d’entraînement : Vérifiez si le modèle a été entraîné sur des données pertinentes pour votre domaine d’application. Par exemple, certains modèles sont spécialisés dans des domaines comme la médecine, le droit, ou la programmation.\nLicence et restrictions : Assurez-vous que la licence du modèle est compatible avec votre utilisation (personnelle, académique, ou commerciale).\nCompatibilité avec Ollama : Consultez la documentation officielle ou utilisez la commande suivante pour voir les modèles compatibles avec Ollama : [https://ollama.com/search](https://ollama.com/search)\nTests et évaluation : Une fois le modèle téléchargé, effectuez des tests pour évaluer ses performances sur vos cas d’utilisation spécifiques.\n\nEn cas de doute, commencez par un modèle généraliste comme “llama2” et ajustez votre choix en fonction des résultats obtenus.\nPour plus d’infos cf. https://shs.cairn.info/revue-francaise-de-sociologie-2014-3-page-563?lang=fr"
  },
  {
    "objectID": "iaSem1.html#usages-et-limites",
    "href": "iaSem1.html#usages-et-limites",
    "title": "Séminaire IA - 1",
    "section": "Usages et limites",
    "text": "Usages et limites\n\nUsage en ligne de commande\n\nlancer ollama :\n\nollama serve\n\nUtiliser un modèle :\n\nollama run deepseek-r1\n\nCommencer une conversation :\n\nA quoi servent les humanités numériques ?\nLa réponse s’affiche dans le terminal :\nThinking...\nHmm, l'utilisateur demande à quoi servent les humanités numériques. C'est \nune question assez large mais pertinente sur un domaine émergent dans le \nmonde académique.\n\nJe me demande si l'utilisateur est un étudiant en lettres qui explore ce \nsujet pour la première fois, ou peut-être un professionnel curieux de \ncomprendre comment ces disciplines s'adaptent aux technologies modernes. \nLa question semble simple mais elle cache probablement une interrogation \nsur la pertinence des humanités dans notre époque numérique.\n\nBon, commençons par rappeler que les humanités numériques ne sont pas \nsimplement \"les humanités avec un ordinateur\". C'est un bouleversement \nfondamental de la manière d'aborder ces études. Je devrais structurer ma \nréponse en plusieurs axes clés plutôt qu'une simple liste.\n\nD'abord, il faut souligner le changement de paradigme : les humanités ne \nsont plus seulement des études traditionnelles mais utilisent maintenant \ndes méthodes numériques. L'utilisateur pourrait se demander si c'est juste \nun gadget technologique ou une réelle transformation intellectuelle.\n\nEnsuite, je devrais mentionner l'accessibilité - parce que c'est souvent \nle point négligé dans ces discussions. Les archives sont accessibles à des \nmillions d'étudiants et de chercheurs qui n'en auraient pas autrement. \nCela répond peut-être à une préoccupation plus large sur l'accès aux \nconnaissances.\n\nAh, et les analyses quantitatives ! Beaucoup de gens perçoivent encore les \nhumanités comme strictement qualitativas. Mais en réalité, des outils \ncomme le texte analytique outext-mining permettent de poser des questions \nnouvelles sur les œuvres littéraires par exemple.\n\nJe devrais aussi parler de la collaboration entre chercheurs - parce que \nl'utilisateur semble intéressé par l'impact sociétal. Les projets \ncollaboratifs internationaux sont un aspect important souvent sous-estimé.\n\nEt bien sûr, le rôle dans la critique culturelle est crucial. Dans notre \nsociété numérique hyper-accommodée, les humanités numériques offrent une \nperspective nécessaire sur comment ces technologies façonnent nos pensées \net nos valeurs.\n\nJe sens que l'utilisateur pourrait avoir besoin d'exemples concrets pour \ncomprendre concrètement l'utilité de ce domaine. Je devrais inclure \nquelques applications pratiques tout au long de ma réponse plutôt que \njuste des concepts abstraits.\n\nFinalement, je dois souligner que les humanités numériques ne remplacent \npas la lecture physique ou le travail manuel - c'est une complémentation, \nnon une substitution. Cela répond peut-être à un préjugé qui circule sur \nce sujet.\n...done thinking.\n\nLes humanités numériques (ou digital humanities) sont un domaine interdisciplinaire qui combine les méthodes et les approches des humanités traditionnelles avec les technologies numériques.\nVoici leurs principales utilisations et objectifs :\n\nÉtude du numérique lui-même :\n\nAnalyse des phénomènes numériques culturels : Examiner comment le numérique influence la création, la distribution, la réception et l’interprétation culturelle (textes, images, sons, films).\nComprendre les implications sociales : Explorer comment les technologies numériques modifient nos modes de vie, notre communication, notre accès aux informations, notre travail intellectuel.\n\nMise à disposition du patrimoine culturel :\n\nNumérisation d’archives et manuscrits : Présenter en ligne des documents historiques, littéraires, artistiques ou musicaux qui seraient autrement difficiles d’accès.\nAccès universelisé : Rendre le patrimoine culturel accessible à un public plus large, indépendamment de l’endroit ou du moment où il se trouve.\n\nAnalyse et recherche avancée :\n\nTraitement automatique des textes (text mining) : Utiliser des logiciels pour analyser des corpus littéraires, historiques ou philosophiques très volumineux (“analyse de fouille de texte”) pour identifier des thèmes, des tendances, des styles stylistiques ou effectuer une cooccurrence.\nAnalyse d’images et multimédias : Développer ou utiliser des outils pour étudier les images numériques (recognition faciale dans l’art classique ? analyse de style visuel ?), le cinéma, la photographie numérique.\n\nCréation et innovation :\n\nHypertexte et multimodalité : Exploiter la nature non linéaire du numérique pour créer de nouvelles formes d’expression artistique ou littéraire (oeuvres hypertextuelles, projets multimodaux).\nReprésentation visuelle des données complexes : Développer des outils pour visualiser graphiquement des concepts humanitaires difficiles à appréhender, comme la chronologie historique, les relations entre personnages dans un texte shakespearien, ou l’évolution d’un corpus linguistique.\n\nCollaboration et partage :\n\nProjets collaboratifs en ligne : Faciliter la collaboration entre chercheurs du monde entier sur des bases de données communes (comme le projet Gallica).\nVeille numérique : Permettre aux chercheurs d’observer, analyser et documenter l’utilisation publique des technologies numériques.\n\nRédaction et diffusion électronique :\n\nÉdition numérique : Proposer de nouvelles méthodes pour éditer et présenter les textes anciens ou modernes.\nDiffusion des travaux académiques : Publier des recherches, des conférences ou des ressources pédagogiques numériques en open access.\n\nEnseignement :\n\nRessources pédagogiques interactives : Développer des outils et des méthodes d’enseignement innovants utilisant le numérique.\nPréservation du savoir : Numériser les contenus pédagogiques pour assurer leur préservation.\n\n\n\nEn résumé, les humanités numériques servent à :\n\nExplorer de nouvelles formes de culture et d’expression engendrées par le numérique.\nÉtudier l’impact sociétal des technologies numériques.\nDémocratiser l’accès aux connaissances et au patrimoine culturel.\nDévelopper de nouvelles méthodes analytiques pour traiter les données textuelles, visuelles ou sonores issues du numérique ou adaptées à la recherche humaniste.\nInnover dans la création artistique/littéraire et le travail intellectuel.\nAméliorer l’enseignement des humanités.\n\n\nElles ne remplacent pas les humanités traditionnelles (lire, analyser, interpréter) mais les enrichissent techniquement, méthodologiquement et accessiblement.\n\n\nFinir une conversation : Quitter le terminal\n\n\n\nExtraction de données dans une image\nCes exemples sont liés au projet de recherche “Freloche” qui a pour objectif de cartographier les souvenirs en mettant en scène les analogies du jardin et de la chasse aux papillons pour stimuler les réactions mémorielles des participants avec des images issues de collections numérisées.\n\nNous menons une archéologie des créations à Paris 8 en :\n\nconcevant un environnement numérique de captation des souvenirs et d’exploration des récits mémoriels…\ninitiant un dialogue à travers le temps (la mellification) qui prend plusieurs formes : focus groupe, entretiens individuels…\n\n\nDans ce cadre, nous voulons explorer les bibliothèques des participants pour créer des relations entre eux sur la base de références communes.\n\nExemple de scénario à mettre en place pour cette mise en relation.\n\ndemander aux participants de photographier les étagères de leur bibliothèque à partir d’une application qui ajoute la photo dans une base de données\ntraiter la photo pour en extraire une liste de livre\nrendre la photo cliquable pour que chaque livre renvoie sa référence\nproposer la photo aux autres participants pour qu’ils réagissent\n\n\nL’étape 2. qui consiste à identifier chaque livre présent sur l’étagère est très fastidieuse si elle se fait à la main :\n\nComment utiliser l’IA pour faire ce travail ?\n\nOllama-OCR\n“Ollama-OCR” est une application de reconnaissance optique de caractères (OCR, pour Optical Character Recognition). Ollama-OCR s’utilise à partir d’un script Python conçu pour effectuer des tâches d’OCR, en utilisant des modèles d’intelligence artificielle ou des outils spécifiques.\n\nInstallation : suivre les instructions de cette page : https://github.com/imanoop7/Ollama-OCR\nCréer un script python : one.py\nmodifier le script python :\n\nPréciser :\n\nl’adresse de l’image \nle prompt spécifique.\n\n\n\nfrom ollama_ocr import OCRProcessor\n\n# Initialize OCR processor\nocr = OCRProcessor(model_name='llama3.2-vision:11b')  # You can use any vision model available on Ollama\n\n# Process an image\nresult = ocr.process_image(\n    image_path=\"/Users/samszo/Sites/freloche/files/Photos-1-001/PXL_20250225_075552954.MP.jpg\", # path to your pdf files \"path/to/your/file.pdf\"\n    format_type=\"markdown\",  # Options: markdown, text, json, structured, key_value\n    custom_prompt=\"Extract all text, focusing on names or book title.\", # Optional custom prompt\n    language=\"French\" # Specify the language of the text\n)\nprint(result)\n\nExecuter le script python :\n\npython one.py\n\nLe résultat s’affiche dans le terminal :\n\nThe image presents a black-and-white photograph of a bookshelf, showcasing a collection of books with their spines facing outward. The books are arranged in a row, with some titles and authors visible, while others are not.\n\nHere is the list of books extracted from the image:\n\n*   \"La Vie Algorithmique\" by Éric Sabir\n*   \"Pour Une Ecologie de L'attention\" by Yves Citton\n*   \"La Couleur Des Idees\" by Yves Citton\n*   \"Bibliothèque Idées\" by Hans Robert Jauß\n*   \"La Vie Algorithmique\" by Éric Sabir\n*   \"Pour Une Ecologie de L'attention\" by Yves Citton\n*   \"La Couleur Des Idees\" by Yves Citton\n*   \"Bibliothèque Idées\" by Hans Robert Jauß\n*   \"La Vie Algorithmique\" by Éric Sabir\n*   \"Pour Une Ecologie de L'attention\" by Yves Citton\n*   \"La Couleur Des Idees\" by Yves Citton\n*   \"Bibliothèque Idées\" by Hans Robert Jauß\n*   \"La Vie Algorithmique\" by Éric Sabir\n*   \"Pour Une Ecologie de L'attention\" by Yves Citton\n*   \"La Couleur Des Idees\" by Yves Citton\n*   \"Bibliothèque Idées\" by Hans Robert Jauß\n*   \"La Vie Algorithmique\" by Éric Sabir\n*   \"Pour Une Ecologie de L'attention\" by Yves Citton\n*   \"La Couleur Des Idees\" by Yves Citton\n*   \"Bibliothèque Idées\" by Hans Robert Jauß\n*   \"La Vie Algorithmique\" by Éric Sabir\n*   \"Pour Une Ecologie de L'attention\" by Yves Citton\n*   \"La Couleur Des Idees\" by Yves Citton\n*   \"Bibliothèque Idées\" by Hans Robert Jauß\n*   \"La Vie Algorithmique\" by Éric Sabir\n*   \"Pour Une Ecologie de L'attention\" by Yves Citton\n*   \"La Couleur Des Idees\" by Yves Citton\n*   \"Bibliothèque Idées\" by Hans Robert Jauß\n*   \"La Vie Algorithmique\" by Éric Sabir\n*   \"Pour Une Ecologie de L'attention\" by Yves Citton\n*   \"La Couleur Des Idees\" by Yves Citton\n*   \"Bibliothèque Idées\" by Hans Robert Jauß\n*   \"La Vie Algorithmique\" by Éric Sabir\n*   \"Pour Une Ecologie de L'attention\" by Yves Citton\n*   \"La Couleur Des Idees\" by Yves Citton\n*   \"Bibliothèque Idées\" by Hans Robert Jauß\n*   \"La Vie Algorithmique\" by Éric Sabir\n*   \"Pour Une Ecologie de L'attention\" by Yves Citton\n*   \"La Couleur Des Idees\" by Yves Citton\n*   \"Bibliothèque Idées\" by Hans Robert Jauß\n*   \"La Vie Algorithmique\" by Éric Sabir\n*   \"Pour Une Ecologie de L'attention\" by Yves Citton\n*   \"La Couleur Des Idees\" by Yves Citton\n*   \"Bibliothèque Idées\" by Hans Robert Jauß\n*   \"La Vie Algorithmique\" by Éric Sabir\n*   \"Pour Une Ecologie de L'attention\" by Yves Citton\n*   \"La Couleur Des Idees\" by Yves Citton\n*   \"Bibliothèque Idées\" by Hans Robert Jauß\n*   \"La Vie Algorithmique\" by Éric Sabir\n*   \"Pour Une Ecologie de L'attention\" by Yves Citton\n*   \"La Couleur Des Idees\" by Yves Citton\n*   \"Bibliothèque Idées\" by Hans Robert Jauß\n*   \"La Vie Algorithmique\" by Éric Sabir\n*   \"Pour Une Ecologie de L'attention\" by Yves Citton\n*   \"La Couleur Des Idees\" by Yves Citton\n*   \"Bibliothèque Idées\" by Hans Robert Jauß\n*   \"La Vie Algorithmique\" by Éric Sabir\n*   \"Pour Une Ecologie de L'attention\" by Yves Citton\n*   \"La Couleur Des Idees\" by Yves Citton\n*   \"Bibliothèque Idées\" by Hans Robert Jauß\n*   \"La Vie Algorithmique\" by Éric Sabir\n*   \"Pour Une Ecologie de L'attention\" by Yves Citton\n*   \"La Couleur Des Idees\" by Yves Citton\n*   \"Bibliothèque Idées\" by Hans Robert Jauß\n*   \"La Vie Algorithmique\" by Éric Sabir\n*   \"Pour Une Ecologie de L'attention\" by Yves Citton\n\nrésultats\n\nle processus de traitement prend du temps\nle résultat comporte des erreurs :\n\ndoublons,\nmauvaise orthographe\n\ndes actions supplémentaires sont nécessaires\n\noptimiser le prompt\ntester d’autres modèles\ntrouver les références ISBN de chaque livre\ncartographier la photo pour sélectionner une référence en cliquant sur un livre\nintégration du code dans Freloche\n\n\n\n\n\nGemini\nGemini est une plateforme d’intelligence artificielle développée par Google DeepMind, conçue pour intégrer des capacités avancées de traitement du langage naturel et de raisonnement. Elle combine des modèles de langage de pointe avec des fonctionnalités de planification et de résolution de problèmes, permettant des interactions plus dynamiques et contextuelles.\n\nFonctionnalités principales de Gemini :\n\nCompréhension contextuelle avancée : Gemini peut interpréter des requêtes complexes en tenant compte du contexte global.\nRaisonnement multimodal : Capacité à traiter et à intégrer des données provenant de plusieurs sources (texte, images, etc.).\nAdaptabilité : Gemini peut être personnalisé pour des cas d’utilisation spécifiques, comme l’éducation, la recherche ou les applications commerciales.\nSécurité et éthique : Conçu pour minimiser les biais et garantir des interactions responsables.\n\n\n\nApplications potentielles :\n\nAssistance à la recherche académique.\nGénération de contenu créatif.\nAnalyse de données complexes.\nAutomatisation des tâches dans des environnements professionnels.\n\nPour plus d’informations, consultez la page officielle : Google DeepMind Gemini.\n\n\nextraction des références de livre dans une image\n\n\nAprès des demandes pour :\n\nun traitement de 10 images supplémentaires\nune compilation des listes dans une liste unique sans doublons\n\non obtient le résultat suivant https://docs.google.com/spreadsheets/d/1pRQhTsZtlsM1CV2nANeprvEkq6_Ikm16xbo1tRvBqhE/edit?usp=sharing\n\n\n\nrésultats\n\nle processus est payant : 21 € / mois https://gemini.google/subscriptions/\nle résultat comporte des erreurs :\n\ndes références n’ont pas été trouvées\n\ndes actions supplémentaires sont nécessaires\n\ncartographier la photo pour sélectionner une référence en cliquant sur un livre\nintégration du code dans Freloche\n\n\n\n\n\ncv-book-svg : Make your bookshelf clickable\nUse computer vision to generate an SVG that you can overlay onto a photo of your bookshelf that lets you click on each book to find out more information.\n\npour plus de détails et le processus d’installation cf. https://github.com/capjamesg/cv-book-svg\nlancement de la commande avec le lien vers la photo et le résultat\n\ncd cv-book-svg\npython3 grounded.py --image=/Users/samszo/Sites/freloche/files/Photos-1-001/PXL_20250225_074724229.jpg --output=annotation1.html\n\non obtient le document : freloche/annotation1.html\n\n\nrésultats\n\nle processus est payant : 0,07 $ / image https://platform.openai.com/settings/organization/usage Autres coûts : https://platform.openai.com/docs/pricing\nle résultat comporte des erreurs :\n\ndes livres ne sont pas cartographiés,\ndes références n’ont pas été trouvées,\ndes références sont fausses\n\ndes actions supplémentaires sont nécessaires\n\nintégration du code dans Freloche\n\n\n\n\n\n\nUtilisation d’AnythingLLM\nAnythingLLM est une plateforme qui permet de déployer et d’exploiter des modèles de langage (LLMs) de manière flexible et personnalisée. Elle offre des outils pour intégrer des modèles de langage dans des applications spécifiques, tout en permettant une gestion simplifiée des données et des interactions.\n\n\nFonctionnalités principales d’AnythingLLM :\n\nDéploiement local ou cloud : Vous pouvez exécuter des modèles localement ou les héberger dans le cloud selon vos besoins.\nPersonnalisation des modèles : Ajustez les modèles pour répondre à des cas d’utilisation spécifiques en utilisant des données personnalisées.\nGestion des données : Intégrez et organisez vos données pour optimiser les performances des modèles.\nInterface utilisateur conviviale : Fournit une interface simple pour interagir avec les modèles et configurer les paramètres.\nCompatibilité avec plusieurs modèles : Supporte différents modèles de langage, qu’ils soient open source ou propriétaires.\n\n\n\nCas d’utilisation d’AnythingLLM :\n\nRecherche et analyse : Exploitez les capacités des LLMs pour extraire des informations pertinentes à partir de grandes quantités de données.\nAutomatisation des tâches : Automatisez des processus répétitifs ou complexes grâce à des modèles de langage.\nApplications conversationnelles : Créez des chatbots ou des assistants virtuels pour répondre aux besoins des utilisateurs.\nPersonnalisation des réponses : Adaptez les réponses des modèles en fonction du contexte ou des préférences des utilisateurs.\n\nPour plus d’informations, consultez la documentation officielle : AnythingLLM GitHub.\n\nPour installer l’application sur votre machine :\n\nPour une application autonome : https://anythingllm.com/desktop\nPour une conteneur Docker : https://hub.docker.com/r/mintplexlabs/anythingllm\n\n\n\nExemple d’utilisation : chatbot avec RAG\nAnythingLLM permet de gérer facilement l’ajout de documents pour qu’ils soient pris en compte dans des conversations avec les agents en utilisant des techniques de RAG.\n\nQu’est-ce que le RAG ?\nRAG (Retrieval-Augmented Generation) est une technique qui combine les capacités des modèles de langage (LLMs) avec des systèmes de récupération d’informations. L’objectif est d’améliorer la pertinence et la précision des réponses générées par les modèles en s’appuyant sur des données externes.\nPour une veille sur la RAG : https://www.diigo.com/user/luckysemiosis?query=RAG\n\n\nFonctionnement du RAG :\n\nRécupération d’informations : Le système interroge une base de données ou un ensemble de documents pour extraire les informations les plus pertinentes en fonction de la requête de l’utilisateur.\nGénération augmentée : Les informations récupérées sont ensuite utilisées comme contexte pour guider le modèle de langage dans la génération de réponses.\n\n\n\nAvantages du RAG :\n\nPrécision accrue : En s’appuyant sur des données spécifiques, le modèle peut fournir des réponses plus précises et adaptées.\nRéduction des hallucinations : Le modèle est moins susceptible de générer des informations incorrectes ou inventées.\nPersonnalisation : Permet d’adapter les réponses en fonction d’un domaine ou d’un corpus spécifique.\n\n\n\nCas d’utilisation :\n\nRecherche documentaire : Extraction d’informations pertinentes à partir de grandes bases de données.\nAssistants virtuels : Fournir des réponses précises basées sur des documents internes ou des FAQ.\nApplications éducatives : Aider les étudiants ou chercheurs à trouver des informations spécifiques dans des corpus académiques.\n\nEn résumé, le RAG est une approche puissante pour combiner les forces des modèles de langage et des systèmes de récupération d’informations, offrant des réponses plus fiables et contextuelles.\n\n\nFaire du RAG avec AnythingLLM\n\n\n\nAjouter manuellement des documents\n\n\n\nAjouter des documents à partir d’une base de données\nCet exemple est lié au projet de recherche ExploDeleuze : Explorer les cours de Deleuze avec l’IA.\n\nLes objectifs de ce projet sont multiples :\n\nConcevoir, développer et tester un dispositif numérique de transcription automatique des collections sonores\nConcevoir, développer et tester des applications Web qui utilisent ces transcriptions\nTranscrire les cours de Gilles Deleuze disponibles dans Gallica comme preuve de concept\nPréparer un projet de plus grande ampleur (ANR, Europe…)\n\n\nPour plus d’informations : https://docs.google.com/document/d/1uqB_7DApJItX4Jonmr8JSefgm2tLvlMlyhh4SnsrtqQ/edit?usp=sharing.\n\nProcessus d’ajout de document\n\n\n\nDiagramme de Flux\n\n\n\n\nUtilisation du RAG dans une application tierce"
  },
  {
    "objectID": "iaSem1.html#bilans",
    "href": "iaSem1.html#bilans",
    "title": "Séminaire IA - 1",
    "section": "Bilans",
    "text": "Bilans\n\nL’usage de l’IA prends beaucoup de temps pour :\n\nla veille nécessaire pour trouver :\n\nles bons modèles,\nles bons outils\n\npour bricoler une solution en lien avec un projet\n\nLe passage par des IA de plateforme (ChatGPT, Gemini…) raccourci le temps nécessaire pour l’usage de l’IA en échange d’argent.\nDans le cas, d’un usage lié à la recherche et l’enseignant, devons-nous :\n\ntransformer le slogan :\n\n“Le temps c’est de l’argent”\nen “Le temps c’est de la connaissance”.\n\nmettre de coté les IA de plateforme au profit des IA bricolées localement\n\nmême si cela prend plus de temps,\nmême si l’efficacité est moins spectaculaire\n\n\n\nQuels pouvoirs souhaitons-nous développer ?"
  },
  {
    "objectID": "iaSem1.html#a-suivre",
    "href": "iaSem1.html#a-suivre",
    "title": "Séminaire IA - 1",
    "section": "A suivre",
    "text": "A suivre\n\nDévelopper ses propres modèles\nMettre en place des processus automatiques utilisant des agents cf. Veuille sur les agents"
  }
]